{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ViperLib 1.0 (VIPER v3.1)",
      "provenance": [],
      "collapsed_sections": [
        "rAZhBWh_g7-o",
        "cM6gWp8zigUF",
        "LHowApy6hBxQ",
        "9vWqy4uehE7u",
        "alATTjXwATbN",
        "LBmP81a8kaIb",
        "3rB2bar-ke5T"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c69cde059be74441905a863ec5885662": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FileUploadModel",
          "state": {
            "_view_name": "FileUploadView",
            "_counter": 0,
            "style": "IPY_MODEL_c1440ff9b80d45e3a319de8aa394c36e",
            "_dom_classes": [],
            "description": "Upload",
            "multiple": false,
            "_model_name": "FileUploadModel",
            "data": [
              null
            ],
            "button_style": "",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "accept": "",
            "_view_count": null,
            "disabled": false,
            "_view_module_version": "1.5.0",
            "error": "",
            "description_tooltip": null,
            "metadata": [
              {
                "name": "desk3.jpg",
                "type": "image/jpeg",
                "size": 10737,
                "lastModified": 1626894088599
              }
            ],
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_dc37a756828e4d9ab8f7a8f7d7376c7f",
            "icon": "upload"
          }
        },
        "c1440ff9b80d45e3a319de8aa394c36e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ButtonStyleModel",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "button_color": null,
            "font_weight": "",
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "dc37a756828e4d9ab8f7a8f7d7376c7f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rAZhBWh_g7-o"
      },
      "source": [
        "# Helper"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mzDGTj5IUl6_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb046029-4f1c-4f00-b8fc-a4146da646ef"
      },
      "source": [
        "#######################################################################\n",
        "# Helper\n",
        "#######################################################################\n",
        "import logging\n",
        "\n",
        "logging.basicConfig(\n",
        "        level=logging.INFO, format=\"%(asctime)s %(levelname)s:%(message)s\"\n",
        "    )\n",
        "\n",
        "logging.info(\"Loading libraries, takes aproximately 4 seconds.\")\n",
        "# Libraries that will be needed for everything to run\n",
        "import cv2 as cv # used for handling the image aspect\n",
        "# import tarfile # used to untar the model downloaded\n",
        "# import shutil\n",
        "# import urllib.request # used to download\n",
        "import os # file handling\n",
        "import tensorflow as tf # used for detections model\n",
        "import numpy as np # V1.2, added to fix adv noise saving.\n",
        "import urllib\n",
        "\n",
        "logging.info('Done.')\n",
        "\n",
        "# Helper function which downloads from url\n",
        "def Download(base_url, file_name):\n",
        "  if file_name not in os.listdir():\n",
        "    logging.info('Downloading ' + file_name)\n",
        "    import urllib.request\n",
        "\n",
        "    url = base_url + file_name\n",
        "    urllib.request.urlretrieve(url, file_name)\n",
        "    logging.info('Download Complete')\n",
        "\n",
        "    # untar downloaded file if it is a tar file\n",
        "    if file_name.find('.tar.gz') != -1:\n",
        "      logging.info(\"Extracting \" + file_name)\n",
        "      import tarfile\n",
        "      import shutil\n",
        "      \n",
        "      dir_name = file_name[0:-len('.tar.gz')]\n",
        "\n",
        "      if os.path.exists(dir_name):\n",
        "        shutil.rmtree(dir_name) \n",
        "\n",
        "      tarfile.open(file_name, 'r:gz').extractall('./')\n",
        "      logging.info(\"Extraction Complete\")\n",
        "  else:\n",
        "    logging.info(file_name + ' already exists.')\n",
        "\n",
        "# Helper function which downloads the model, makes the object_classes, and returns it for later use.\n",
        "def download_model():\n",
        "  Download('https://raw.githubusercontent.com/nightrome/cocostuff/master/','labels.txt')\n",
        "  Download('http://download.tensorflow.org/models/object_detection/', 'ssd_mobilenet_v1_coco_2018_01_28.tar.gz')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-07-28 00:49:06,457 INFO:Loading libraries, takes aproximately 4 seconds.\n",
            "2021-07-28 00:49:08,761 INFO:Done.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IrdHCI-pitMb"
      },
      "source": [
        "# Helper function which loads the model and later runs the model for every image\n",
        "class Model():\n",
        "  def __init__(self):\n",
        "    download_model() # makes object class dictionary accessible later\n",
        "\n",
        "    # Code from here downward (but still init) are a list of lines that must be ran before running the model\n",
        "    self.outputs = (\n",
        "      'num_detections:0',\n",
        "      'detection_classes:0',\n",
        "      'detection_scores:0',\n",
        "      'detection_boxes:0',\n",
        "    )\n",
        "\n",
        "    self.frozen_graph = os.path.join('ssd_mobilenet_v1_coco_2018_01_28', 'frozen_inference_graph.pb')\n",
        "    \n",
        "    with tf.io.gfile.GFile(self.frozen_graph, \"rb\") as f:\n",
        "      self.graph_def = tf.compat.v1.GraphDef()\n",
        "      self.loaded = self.graph_def.ParseFromString(f.read())\n",
        "  \n",
        "  # Runs Model\n",
        "  def run_model(self,input_image):\n",
        "    \n",
        "    def wrap_graph(graph_def, inputs, outputs, print_graph=False):\n",
        "      wrapped = tf.compat.v1.wrap_function(\n",
        "        lambda: tf.compat.v1.import_graph_def(self.graph_def, name=\"\"), [])\n",
        "\n",
        "      return wrapped.prune(\n",
        "        tf.nest.map_structure(wrapped.graph.as_graph_element, inputs),\n",
        "        tf.nest.map_structure(wrapped.graph.as_graph_element, outputs))\n",
        "    \n",
        "    logging.info('Running model.')  \n",
        "    model = wrap_graph(graph_def=self.graph_def, inputs=[\"image_tensor:0\"], outputs=self.outputs)\n",
        "    tensor = tf.convert_to_tensor([input_image], dtype=tf.uint8)\n",
        "    detections = model(tensor)\n",
        "    logging.info('Done.')\n",
        "\n",
        "    return detections"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cM6gWp8zigUF"
      },
      "source": [
        "# VIPER Helpers\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "doa4aq93ih7t"
      },
      "source": [
        "#######################################################################\n",
        "# VIPER Helpers\n",
        "#######################################################################\n",
        "\n",
        "# Gets a box bound, an image, and returns the actual pixel coordinates on the image\n",
        "def VIPER_COCO_box_to_pixels(box_bounds, cv2_image):\n",
        "    y1 = int((box_bounds[0]*cv2_image.shape[0]).numpy())\n",
        "    x1 = int((box_bounds[1]*cv2_image.shape[1]).numpy())\n",
        "    y2 = int((box_bounds[2]*cv2_image.shape[0]).numpy())\n",
        "    x2 = int((box_bounds[3]*cv2_image.shape[1]).numpy())\n",
        "    \n",
        "    return [x1,x2,y1,y2]\n",
        "\n",
        "# Returns if a number is private or note\n",
        "def VIPER_COCO_priv_or_not(class_num):\n",
        "  if class_num in [12, 14, 30, 33, 46, 63, 65, 66, 70, 71, 72, 73, 74, 75, 76, 77, 85, 110, 133,31,69,3]:\n",
        "    return True\n",
        "  else:\n",
        "    return False\n",
        "\n",
        "# Returns a tuple of (num_of_privates, num_of_non_privates)\n",
        "def VIPER_COCO_priv_and_not(detected_classes_list):\n",
        "  num_private = 0\n",
        "  num_non_private = 0 \n",
        "\n",
        "  for i in detected_classes_list:\n",
        "    if VIPER_COCO_priv_or_not(int(i)):\n",
        "      num_private += 1\n",
        "    else:\n",
        "      num_non_private += 1\n",
        "  return num_private, num_non_private \n",
        "\n",
        "# IMPORTANT! MAY NEED CHANGING\n",
        "def VIPER_object_blur(cv2_image, x1, x2, y1, y2, blurAmount):\n",
        "    blurred_object = cv2_image[y1:y2,x1:x2]\n",
        "    ksize = (blurAmount,blurAmount)\n",
        "      \n",
        "    blurred_object = cv.blur(blurred_object, ksize, cv.BORDER_DEFAULT)\n",
        "    cv2_image[y1:y2,x1:x2] = blurred_object\n",
        "\n",
        "    return cv2_image\n",
        "\n",
        "# IMPORTANT! MAY NEED CHANGING\n",
        "def VIPER_object_block(cv2_image, x1, x2, y1, y2, color):\n",
        "    thickness = -1\n",
        "    cv.rectangle(cv2_image,(x1,y1),(x2,y2), color, thickness)\n",
        "\n",
        "    return cv2_image\n",
        "\n",
        "def privacy_score(image, detections, num_of_detections, detection_classes):\n",
        "  sen = []\n",
        "  vis = []\n",
        "\n",
        "  for i in range(num_of_detections):\n",
        "    box = detections[3][0][i]\n",
        "    box_class = detection_classes[i]\n",
        "    \n",
        "    left, right, bottom, top = VIPER_COCO_box_to_pixels(box, image)\n",
        "    area = (right - left) * (top- bottom)\n",
        "\n",
        "    vis.append(int(VIPER_COCO_priv_or_not(box_class)))\n",
        "    sen.append(area / (image.shape[0] * image.shape[1]))\n",
        "  \n",
        "  return (np.sum(np.array(sen) * np.array(vis)))"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pp6PLTKtjAtS"
      },
      "source": [
        "#######################################################################\n",
        "# Image Blueprint\n",
        "#\n",
        "# Usage: variable_name = Image(Image_Path)\n",
        "#\n",
        "# Variables:\n",
        "# - image = cv2 image that will be manipulated with manipulators\n",
        "# - original = backup of cv2 image just in case\n",
        "# - detections = model results\n",
        "# - num_of_detections = number of detections found in the image\n",
        "# - detection_classes = list of classes from detected objects. ie: [17,18,18]\n",
        "# - private_classes  = list of list. Inner list holds object class number and if they're private or not. ie. [[17, False],[18, False],[18, False]]\n",
        "# - privacy_score = a score based on an equation. The lower, the better.\n",
        "#######################################################################\n",
        "class Image():\n",
        "  def __init__(self, image_path):\n",
        "    if image_path in os.listdir():\n",
        "      self.image = cv.imread(image_path)\n",
        "      self.image=cv.cvtColor(self.image,cv.COLOR_BGR2RGB)\n",
        "      \n",
        "      self.original = cv.imread(image_path)\n",
        "      self.original=cv.cvtColor(self.original,cv.COLOR_BGR2RGB)\n",
        "    else:\n",
        "      req = urllib.request.urlopen(image_path)\n",
        "      arr = np.asarray(bytearray(req.read()), dtype=np.uint8)\n",
        "      self.image = cv.imdecode(arr, -1)\n",
        "      \n",
        "      self.original = cv.imdecode(arr, -1)\n",
        "\n",
        "\n",
        "    self.detections = Model().run_model(self.image)\n",
        " \n",
        "    \n",
        "    self.private_classes = []\n",
        "\n",
        "    self.num_of_detections = len([x for x in self.detections[3][0] if not ((x == self.detections[3][0][-1])[0])])\n",
        "    self.detection_classes = [self.detections[1][0][x].numpy() for x in range(self.num_of_detections)]\n",
        "\n",
        "    self.privacy_score = privacy_score(self.original, self.detections, self.num_of_detections, self.detection_classes)\n",
        "\n",
        "    self.object_classes = {}\n",
        "\n",
        "    for line in open(\"labels.txt\"):\n",
        "      line = line[:-1]\n",
        "      key, value = line.split(': ')\n",
        "      self.object_classes[int(key)] = value\n",
        "\n",
        "    for i in self.detection_classes:\n",
        "      object_class = int(i)\n",
        "      object_bool = VIPER_COCO_priv_or_not(object_class)\n",
        "\n",
        "      self.private_classes.append([int(object_class), object_bool])\n",
        "\n",
        "  def rerun_model(self):\n",
        "    self.detections_ad = Model().run_model(self.image)\n",
        "    self.num_of_detections_ad = len([x for x in self.detections_ad[3][0] if not ((x == self.detections_ad[3][0][-1])[0])])\n",
        "    self.detection_classes_ad = [self.detections_ad[1][0][x].numpy() for x in range(self.num_of_detections_ad)]\n",
        "\n",
        "    self.privacy_score_ad = privacy_score(self.image, self.detections_ad, self.num_of_detections_ad, self.detection_classes_ad)\n",
        "\n",
        "  def __str__(self):\n",
        "    retString = '\\n' + 'OBJECTS FOUND' + '\\n' + '--------------------------' + '\\n'\n",
        "    for i in range(self.num_of_detections):\n",
        "      retString += str(int(self.detections[2][0][i].numpy() * 100)) +'% ' +self.object_classes[int(self.detection_classes[i])]  + '\\n'\n",
        "    retString += '\\n'+'privacy score before: ' + str(self.privacy_score*100) + '\\n' + \\\n",
        "                 'privacy score after: ' + str(self.privacy_score_ad*100) + '\\n'\n",
        "    \n",
        "    return retString"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LHowApy6hBxQ"
      },
      "source": [
        "# Image Blueprint"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u870DvB2Uije"
      },
      "source": [
        "#######################################################################\n",
        "# Image Blueprint\n",
        "#\n",
        "# Usage: variable_name = Image(Image_Path)\n",
        "#\n",
        "# Variables:\n",
        "# - image = cv2 image that will be manipulated with manipulators\n",
        "# - original = backup of cv2 image just in case\n",
        "# - detections = model results\n",
        "# - num_of_detections = number of detections found in the image\n",
        "# - detection_classes = list of classes from detected objects. ie: [17,18,18]\n",
        "# - private_classes  = list of list. Inner list holds object class number and if they're private or not. ie. [[17, False],[18, False],[18, False]]\n",
        "# - privacy_score = a score based on an equation. The lower, the better.\n",
        "#######################################################################\n",
        "class Image():\n",
        "  def __init__(self, image_path):\n",
        "    if image_path in os.listdir():\n",
        "      self.image = cv.imread(image_path)\n",
        "      self.image=cv.cvtColor(self.image,cv.COLOR_BGR2RGB)\n",
        "      \n",
        "      self.original = cv.imread(image_path)\n",
        "      self.original=cv.cvtColor(self.original,cv.COLOR_BGR2RGB)\n",
        "    else:\n",
        "      req = urllib.request.urlopen(image_path)\n",
        "      arr = np.asarray(bytearray(req.read()), dtype=np.uint8)\n",
        "      self.image = cv.imdecode(arr, -1)\n",
        "      \n",
        "      self.original = cv.imdecode(arr, -1)\n",
        "\n",
        "\n",
        "    self.detections = Model().run_model(self.image)\n",
        " \n",
        "    \n",
        "    self.private_classes = []\n",
        "\n",
        "    self.num_of_detections = len([x for x in self.detections[3][0] if not ((x == self.detections[3][0][-1])[0])])\n",
        "    self.detection_classes = [self.detections[1][0][x].numpy() for x in range(self.num_of_detections)]\n",
        "\n",
        "    self.privacy_score = privacy_score(self.original, self.detections, self.num_of_detections, self.detection_classes)\n",
        "\n",
        "    self.object_classes = {}\n",
        "\n",
        "    for line in open(\"labels.txt\"):\n",
        "      line = line[:-1]\n",
        "      key, value = line.split(': ')\n",
        "      self.object_classes[int(key)] = value\n",
        "\n",
        "    for i in self.detection_classes:\n",
        "      object_class = int(i)\n",
        "      object_bool = VIPER_COCO_priv_or_not(object_class)\n",
        "\n",
        "      self.private_classes.append([int(object_class), object_bool])\n",
        "\n",
        "  def rerun_model(self):\n",
        "    self.detections_ad = Model().run_model(self.image)\n",
        "    self.num_of_detections_ad = len([x for x in self.detections_ad[3][0] if not ((x == self.detections_ad[3][0][-1])[0])])\n",
        "    self.detection_classes_ad = [self.detections_ad[1][0][x].numpy() for x in range(self.num_of_detections_ad)]\n",
        "\n",
        "    self.privacy_score_ad = privacy_score(self.image, self.detections_ad, self.num_of_detections_ad, self.detection_classes_ad)\n",
        "\n",
        "  def __str__(self):\n",
        "    retString = '\\n' + 'OBJECTS FOUND' + '\\n' + '--------------------------' + '\\n'\n",
        "    for i in range(self.num_of_detections):\n",
        "      retString += str(int(self.detections[2][0][i].numpy() * 100)) +'% ' +self.object_classes[int(self.detection_classes[i])]  + '\\n'\n",
        "    retString += '\\n'+'privacy score before: ' + str(self.privacy_score*100) + '\\n' + \\\n",
        "                 'privacy score after: ' + str(self.privacy_score_ad*100) + '\\n'\n",
        "    \n",
        "    return retString"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9vWqy4uehE7u"
      },
      "source": [
        "# Modifiers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Up-gga0BUrzy"
      },
      "source": [
        "#######################################################################\n",
        "# Image Modifiers\n",
        "#######################################################################\n",
        "\n",
        "# blur\n",
        "def VIPER_blur(ImageType):\n",
        "  num_of_detections = ImageType.num_of_detections\n",
        "  detection_classes = ImageType.detection_classes\n",
        "\n",
        "  for i in range(num_of_detections):\n",
        "    box = ImageType.detections[3][0][i]\n",
        "    box_class = ImageType.detections[1][0][i]\n",
        "\n",
        "    if VIPER_COCO_priv_or_not(box_class): \n",
        "      left, right, top, bottom = VIPER_COCO_box_to_pixels(box, ImageType.image)\n",
        "      VIPER_object_blur(ImageType.image,left, right, top, bottom, 300)\n",
        "\n",
        "# block\n",
        "def VIPER_block(ImageType):\n",
        "  num_of_detections = ImageType.num_of_detections\n",
        "  detection_classes = ImageType.detection_classes\n",
        "\n",
        "  for i in range(num_of_detections):\n",
        "    box = ImageType.detections[3][0][i]\n",
        "    box_class = ImageType.detections[1][0][i]\n",
        "\n",
        "    color = (0, 0, 0)\n",
        "    if VIPER_COCO_priv_or_not(box_class):\n",
        "      left, right, top, bottom = VIPER_COCO_box_to_pixels(box, ImageType.image)\n",
        "      VIPER_object_block(ImageType.image, left, right, top, bottom, color)\n",
        "\n",
        "\n",
        "# saliency\n",
        "def VIPER_saliency_modifier(ImageType):\n",
        "  saliency = cv.saliency.StaticSaliencySpectralResidual_create() #This intializes the saliency, and the below code creates a finer image which possibly could be used for instance segmentation\n",
        "\n",
        "  (success, saliencyMap) = saliency.computeSaliency(ImageType.image) # this computes the map\n",
        "  ImageType.image = (saliencyMap * 255).astype(\"uint8\") # type casts and standardizes the image pixels \n",
        "  # threshMap = cv.threshold(saliencyMap, 0, 255, cv.THRESH_BINARY | cv.THRESH_OTSU)[1] #applies thereshold to get binary image from map \n",
        "\n",
        "# adverserial noise - FIX FIX FIX FIX\n",
        "def VIPER_advarserial_modifier(ImageType):\n",
        "  # Helper function to preprocess the image so that it can be inputted in MobileNetV2\n",
        "  def preprocess(image):\n",
        "    image = tf.cast(image, tf.float32)\n",
        "    image = tf.image.resize(image, (224, 224))\n",
        "    image = tf.keras.applications.mobilenet_v2.preprocess_input(image)\n",
        "    image = image[None, ...]\n",
        "    return image\n",
        "\n",
        "  def create_adversarial_pattern(input_image, input_label, pretrained_model):\n",
        "    loss_object = tf.keras.losses.CategoricalCrossentropy()\n",
        "    with tf.GradientTape() as tape:\n",
        "      tape.watch(input_image)\n",
        "      prediction = pretrained_model(input_image)\n",
        "      loss = loss_object(input_label, prediction)\n",
        "      \n",
        "    gradient = tape.gradient(loss, input_image) # Get the gradients of the loss w.r.t to the input image.\n",
        "    signed_grad = tf.sign(gradient) # Get the sign of the gradients to create the perturbation\n",
        "\n",
        "    return signed_grad\n",
        "\n",
        "  pretrained_model = tf.keras.applications.MobileNetV2(include_top=True,weights='imagenet')\n",
        "  pretrained_model.trainable = False\n",
        "\n",
        "  adv_image = preprocess(ImageType.image)\n",
        "  image_probs = pretrained_model.predict(adv_image)\n",
        "\n",
        "  # Get the input label of the image.\n",
        "  labrador_retriever_index = 1\n",
        "  label = tf.one_hot(labrador_retriever_index, image_probs.shape[-1])\n",
        "  label = tf.reshape(label, (1, image_probs.shape[-1]))\n",
        "\n",
        "  perturbations = create_adversarial_pattern(adv_image, label, pretrained_model)\n",
        "\n",
        "  eps = 0.05\n",
        "  adv_x = adv_image + eps*perturbations\n",
        "  adv_x = tf.clip_by_value(adv_x, -1, 1)\n",
        "  ImageType.image = adv_x[0]\n",
        "  ImageType.image = np.clip(ImageType.image, 0, 1)\n",
        "  ImageType.image = (ImageType.image * 255).astype(np.uint8)\n",
        "\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "14mDiDkUUtiU"
      },
      "source": [
        "#######################################################################\n",
        "# Image Handlers\n",
        "#######################################################################\n",
        "\n",
        "# image changer\n",
        "def image_modifier(ImageType, modifier):\n",
        "  if modifier.lower() == \"blur\" or modifier.lower()  == 'br':\n",
        "    VIPER_blur(ImageType)\n",
        "  elif modifier.lower()  == \"block\" or modifier.lower()  == 'bk':\n",
        "    VIPER_block(ImageType)\n",
        "  elif modifier.lower()  == \"noise\" or modifier.lower()  == 'ne':\n",
        "    VIPER_advarserial_modifier(ImageType)\n",
        "  elif modifier.lower()  == \"saliency\" or modifier.lower()  == 'sy':\n",
        "    VIPER_saliency_modifier(ImageType)\n",
        "  else:\n",
        "    logging.info(\"No modifier ran.\")\n",
        "  \n",
        "  image_saver(ImageType)\n",
        "  ImageType.image  = cv.imread('image.jpg')\n",
        "  ImageType.rerun_model()\n",
        "\n",
        "#image saver\n",
        "def image_saver(ImageType):\n",
        "  image=ImageType.image\n",
        "  image=cv.cvtColor(image,cv.COLOR_BGR2RGB)\n",
        "  cv.imwrite('image.jpg',image)\n",
        "\n",
        "# command line\n",
        "def command_line(image_path, modifier):\n",
        "  ImageType = Image(image_path)\n",
        "  image_modifier(ImageType, modifier)\n",
        "  image_saver(ImageType)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "alATTjXwATbN"
      },
      "source": [
        "# Running"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LBmP81a8kaIb"
      },
      "source": [
        "## Uploader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "c69cde059be74441905a863ec5885662",
            "c1440ff9b80d45e3a319de8aa394c36e",
            "dc37a756828e4d9ab8f7a8f7d7376c7f"
          ]
        },
        "id": "g0qcU4S-j9jQ",
        "outputId": "517a53c9-5ab7-49bd-9422-e9da6602ce99"
      },
      "source": [
        "from ipywidgets import FileUpload\n",
        "filename_l=[]\n",
        "\n",
        "def on_upload_change(change):\n",
        "    global filename_l\n",
        "    if not change.new:\n",
        "        return\n",
        "    up = change.owner\n",
        "    for filename,data in up.value.items():\n",
        "        print(f'writing [{filename}] to ./')\n",
        "        filename_l.append(filename)\n",
        "        with open(filename, 'wb') as f:\n",
        "            f.write(data['content'])\n",
        "    up.value.clear()\n",
        "    up._counter = 0\n",
        "\n",
        "upload_btn = FileUpload()\n",
        "upload_btn.observe(on_upload_change, names='_counter')\n",
        "upload_btn"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c69cde059be74441905a863ec5885662",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "FileUpload(value={}, description='Upload')"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "writing [desk3.jpg] to ./\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3rB2bar-ke5T"
      },
      "source": [
        "## Run"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YhHiQ6oFkFl2",
        "outputId": "4163e157-e83f-48db-a167-007f8ebe5d69"
      },
      "source": [
        "a = Image(filename_l[0])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-07-28 00:49:13,519 INFO:Downloading labels.txt\n",
            "2021-07-28 00:49:15,060 INFO:Download Complete\n",
            "2021-07-28 00:49:15,063 INFO:Downloading ssd_mobilenet_v1_coco_2018_01_28.tar.gz\n",
            "2021-07-28 00:49:15,810 INFO:Download Complete\n",
            "2021-07-28 00:49:15,815 INFO:Extracting ssd_mobilenet_v1_coco_2018_01_28.tar.gz\n",
            "2021-07-28 00:49:16,717 INFO:Extraction Complete\n",
            "2021-07-28 00:49:16,820 INFO:Running model.\n",
            "2021-07-28 00:49:24,865 INFO:Done.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KMsyQQ1XlQTG",
        "outputId": "f36390d3-6320-4845-cee3-3029438e748c"
      },
      "source": [
        "image_modifier(a, 'noise')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224.h5\n",
            "14540800/14536120 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-07-28 00:49:32,527 INFO:labels.txt already exists.\n",
            "2021-07-28 00:49:32,529 INFO:ssd_mobilenet_v1_coco_2018_01_28.tar.gz already exists.\n",
            "2021-07-28 00:49:32,635 INFO:Running model.\n",
            "2021-07-28 00:49:39,953 INFO:Done.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0VkjF0WzjraF"
      },
      "source": [
        "image_saver(a)"
      ],
      "execution_count": 17,
      "outputs": []
    }
  ]
}